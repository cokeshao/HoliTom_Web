<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>HoliTom: Holistic Token Merging for Fast Video Large Language Models</title>
  <link rel="icon" type="image/x-icon" href="static/images/holi_tom.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <span style="white-space: nowrap;">HoliTom<img src="static/images/holi_tom.png" alt="HoliTom" style="height: 51px; margin: 0 10px; display: inline-block;"></span>: Holistic Token Merging for Fast Video Large Language Models
            </h1>
            <div class="is-size-4 has-text-centered" style="color: red; font-weight: bold; margin: 20px 0;">
              NeurIPS 2025
            </div>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block">
                <a href="https://cokeshao.github.io/" target="_blank">Kele Shao</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://kd-tao.github.io/" target="_blank">Keda Tao</a><sup>2</sup>,</span>
                  <span class="author-block">
                    <a href="https://canqin.tech/" target="_blank">Can Qin</a><sup>3</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://hxyou.github.io/" target="_blank">Haoxuan You</a><sup>4</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://eclipsess.github.io/yangsui.github.io/" target="_blank">Yang Sui</a><sup>5</sup>,
                  </span>
                  <span class="author-block">
                    <a href="https://huanwang.tech/" target="_blank">Huan Wang</a><sup><sup>2</sup>*</sup>
                  </span>
                  </div>

                  <div class="is-size-5 publication-authors">
                    <span class="author-block"><sup>1</sup>Zhejiang University, <sup>2</sup>Westlake University, <sup>3</sup>Salesforce AI Research, <sup>4</sup>Columbia University, <sup>5</sup>Rice University</span>
                  </div>
                  <div style="font-size:15px">
                    <span><sup>&ast;</sup>Corresponding author: wanghuan [at] westlake [dot] edu [dot] cn</span><br><br>
                  </div>

                  <div class="columns is-centered" style="display: flex; justify-content: center; align-items: center;">
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                        <img src="static/images/zju-logo.svg" alt="Zhejiang University" style="height: 92px; width: auto; object-fit: contain;">
                    </div>
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                        <img src="static/images/westlake.png" alt="Westlake University" style="height: 92px; width: auto; object-fit: contain;">
                    </div>
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                        <img src="static/images/salesforce-with-type-logo.svg" alt="Salesforce AI Research" style="height: 92px; width: auto; object-fit: contain;">
                    </div>
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                        <img src="static/images/Columbia_coat_of_arms_no_crest.svg.png" alt="Columbia University" style="height: 92px; width: auto; object-fit: contain;">
                    </div>
                    <div class="column is-narrow" style="display: flex; justify-content: center; align-items: center;">
                        <img src="static/images/Rice_University_seal.svg.png" alt="Rice University" style="height: 92px; width: auto; object-fit: contain;">
                    </div>
                  </div>


                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.21334" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                    <!-- Supplementary PDF link -->
                    <!-- <span class="link-block">
                      <a href="static/pdfs/supplementary_material.pdf" target="_blank"
                      class="external-link button is-normal is-rounded is-dark">
                      <span class="icon">
                        <i class="fas fa-file-pdf"></i>
                      </span>
                      <span>Supplementary</span>
                    </a>
                  </span> -->

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/cokeshao/HoliTom" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.21334" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>


<!-- Teaser video-->
<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" autoplay controls muted loop height="100%"> -->
        <!-- Your video here -->
        <!-- <source src="static/videos/banner_video.mp4"
        type="video/mp4">
      </video>
      <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2>
    </div>
  </div>
</section> -->
<!-- End teaser video -->

<!-- Teaser image-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img src="static/images/teaser.jpeg" alt="HoliTom" style="height: 95%; width: 95%; object-fit: contain;">
      <h2 class="subtitle" style="text-align: left;">
        <b>Left:</b> We introduce <i>HoliTom</i>, a training-free <u>holi</u>stic <u>to</u>ken <u>m</u>erge method for fast video LLMs. Its key innovation lies in its global, redundancy-aware outer-LLM spatio-temporal compression and robust, token similarity-based inner-LLM compression. <b>Right:</b> The
    Efficiency/Performance trade-off curve of multiple training-free methods on four widely used video understanding benchmarks: MVBench, EgoSchema, LongVideoBench, and VideoMME. Our method, <i>HoliTom</i>, surpasses the SoTA approaches by maintaining 99.1% average performance while reducing FLOPs to 6.9%. 
      </h2>
    </div>
  </div>
</section>
<!-- End teaser image -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Video large language models (video LLMs) excel at video comprehension but face significant computational inefficiency due to redundant video tokens. Existing token pruning methods offer solutions. However, approaches operating within the LLM (inner-LLM pruning), such as FastV, incur intrinsic computational overhead in shallow layers. In contrast, methods performing token pruning before the LLM (outer-LLM pruning) primarily address spatial redundancy within individual frames or limited temporal windows, neglecting the crucial global temporal dynamics and correlations across longer video sequences. This leads to sub-optimal spatio-temporal reduction and does not leverage video compressibility fully. Crucially, the synergistic potential and mutual influence of combining these strategies remain unexplored. To further reduce redundancy, we introduce HoliTom, a novel training-free holistic token merging framework. HoliTom employs outer-LLM pruning through global redundancy-aware temporal segmentation, followed by spatial-temporal merging to reduce visual tokens by over 90%, significantly alleviating the LLM's computational burden. Complementing this, we introduce a robust inner-LLM token similarity-based merging approach, designed for superior performance and compatibility with outer-LLM pruning. Evaluations demonstrate our method's promising efficiency-performance trade-off on LLaVA-OneVision-7B, reducing computational costs to 6.9% of FLOPs while maintaining 99.1% of the original performance. Furthermore, we achieve a 2.28× reduction in Time-To-First-Token (TTFT) and a 1.32× acceleration in decoding throughput, highlighting the practical benefits of our integrated pruning approach for efficient video LLMs inference.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<section class="section">
  <div class="container is-max-desktop has-text-centered">
    
    <!-- Title -->
    <h2 class="title is-3">Overview of our <i>HoliTom</i> method</h2>

    <!-- Text Content -->
    <div class="content has-text-justified">
      <p>
        <i>HoliTom</i> compresses video LLMs across three scopes; the first two are outer-LLM pruning.
        <b>Temporal Merging</b> maximizes temporal compression via global redundancy-aware segmentation, merging similar tokens into their first occurrence. 
        <b>Spatial Merging</b> further reduces redundancy by applying tailored spatial compression based on the characteristics of remaining temporal variations. 
        <b>Inner-LLM Merging</b> leverages attention within the LLM to identify key tokens and merges less important, similar tokens, streamlining information within the LLM.
      </p>
    </div>

    <!-- Image Content -->
    <div class="is-flex is-justify-content-center">
      <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 0 auto;">
        <img src="static/images/overview.jpeg" alt="Method Overview" 
             style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 95%;">
      </figure>
    </div>

  </div>
</section>


<!-- Image carousel -->
<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="margin-bottom: 0.5rem;">Main Results</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
        <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
          <img src="static/images/benchmark.jpeg" alt="Benchmark" 
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 95%;">
        </figure>
        <h2 class="subtitle has-text-centered">
          <b>Overview of our <i>HoliTom</i> method.</b> <b>Best</b> and <b>most efficient</b> results are in bold, <u>second best</u> underlined. All methods are compared on LLaVA-OneVision-7B.
        </h2>
      </div>
      <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
        <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
          <img src="static/images/draw_inference.jpeg" alt="Inference" 
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 95%;">
        </figure>
        <h2 class="subtitle has-text-centered">
          <b>Achieving superior inference.</b> "Other" indicates token pre-processing time (e.g., pooling). Our proposed method reduces Time-To-First-Token (TTFT) by 2.28× and achieves 1.32× higher decoding throughput, outperforming all other token compression methods and the vanilla model.
        </h2>
      </div>
      <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
        <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
          <img src="static/images/diff_backbone.jpeg" alt="Different Backbone" 
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 95%;">
        </figure>
        <h2 class="subtitle has-text-centered">
          <b>Comparison of state-of-the-art methods across benchmarks.</b> <b>Best</b> and <b>most efficient</b> results are in bold, <u>second best</u> underlined.
        </h2>
      </div>
      <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
        <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
          <img src="static/images/vs_fastv.jpeg" alt="Vs FastV"
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 60%;">
        </figure>
        <h2 class="subtitle has-text-centered">
          <b>Left:</b> Performance of our method <i>vs.</i> FastV  when pruning various layers at rate R=50\%. <b>Right:</b> Performance comparison with varying pruning rates at a fixed layer (K=14).
       </h2>
     </div>
     <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
      <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
        <img src="static/images/more_frames.jpeg" alt="More Frames"
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 40%;">
        </figure>
      <h2 class="subtitle has-text-centered">
        Performance <i>vs.</i> number of frames for our method and other token compression methods.
      </h2>
    </div>
  </div>
</div>
</div>
</section>
<!-- End image carousel -->


<section class="hero is-small">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <h2 class="title is-3 has-text-centered" style="margin-bottom: 0.5rem;">More Visualizations</h2>
      <div id="results-carousel" class="carousel results-carousel">
       <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
        <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
          <img src="static/images/challenge_understanding.jpeg" alt="Challenge Understanding" 
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 95%;">
        </figure>
        <h2 class="subtitle has-text-centered">
          <b>Comparison on Challenging Video Understanding.</b> <span style="color: #00B050">Green</span>: correct results, <span style="color: #C00000">Red</span>: incorrect results. Our method is able to produce correct answers on challenging video tasks.
        </h2>
      </div>
     <div class="item" style="min-height: 100%; display: flex; flex-direction: column; justify-content: center;">
      <figure class="image" style="display: flex; justify-content: center; align-items: center; margin: 2rem auto;">
        <img src="static/images/qualitative_generation.jpeg" alt="Qualitative Generation"
               style="border-radius: 12px; box-shadow: 0px 4px 10px rgba(0,0,0,0.1); max-width: 95%;">
        </figure>
      <h2 class="subtitle has-text-centered">
        <b>Comparison on Challenging Video Understanding.</b> <span style="color: #00B050">Green</span>: correct results, <span style="color: #C00000">Red</span>: incorrect results. Our method is able to produce correct answers on challenging video tasks.
      </h2>
    </div>
  </div>
</div>
</div>
</section>


<!--BibTex citation -->
  <section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      <pre><code>@inproceedings{shao2025holitom,
  title={Holitom: Holistic token merging for fast video large language models},
  author={Shao, Kele and Tao, Keda and Qin, Can and You, Haoxuan and Sui, Yang and Wang, Huan},
  booktitle=NeurIPS,
  year={2025}
}</code></pre>
    </div>
</section>
<!--End BibTex citation -->


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the <a href="https://nerfies.github.io" target="_blank">Nerfies</a> project page.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
